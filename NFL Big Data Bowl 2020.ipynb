{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Big Data Bowl 2020 - Data Exploration and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T12:09:27.017825Z",
     "start_time": "2019-11-11T12:09:15.638015Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T12:09:27.027617Z",
     "start_time": "2019-11-11T12:09:27.017825Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.listdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T16:37:54.271005Z",
     "start_time": "2019-11-02T16:37:51.188404Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:24:39.273699Z",
     "start_time": "2019-11-02T12:24:39.266718Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Each row in the file corresponds to a single player's involvement in a single play. The dataset was intentionally joined (i.e. denormalized) to make the API simple. All the columns are contained in one large dataframe which is grouped and provided by PlayId. **This dataset only contains passing plays** (https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/111935#latest-645825)\n",
    "\n",
    "* GameId - a unique game identifier\n",
    "* PlayId - a unique play identifier\n",
    "* Team - home or away\n",
    "* X - player position along the long axis of the field. See figure below.\n",
    "* Y - player position along the short axis of the field. See figure below.\n",
    "* S - speed in yards/second\n",
    "* A - acceleration in yards/second^2\n",
    "* Dis - distance traveled from prior time point, in yards (by that player?)\n",
    "* Orientation - orientation of player (deg)\n",
    "* Dir - angle of player motion (deg)\n",
    "* NflId - a unique identifier of the player\n",
    "* DisplayName - player's name\n",
    "* JerseyNumber - jersey number\n",
    "* Season - year of the season<br>\n",
    "The data is gathere from two seasons: 2017/2018 for which the value is 2017 and 2018/19 for which the value is 2018\n",
    "* YardLine - the yard line of the line of scrimmage\n",
    "* Quarter - game quarter (1-5, 5 == overtime)\n",
    "* GameClock - time on the game clock<br>\n",
    "The game clock starts at 15:00:00 at the beginning of every quarter and then goes until 00:00:00 when the quarter ends. Then the clock is reset to 15 mins when the new quarter starts.\n",
    "* PossessionTeam - team with possession\n",
    "* Down - the down (1-4)\n",
    "* Distance - yards needed for a first down\n",
    "* FieldPosition - which side of the field the play is happening on\n",
    "* HomeScoreBeforePlay - home team score before play started\n",
    "* VisitorScoreBeforePlay - visitor team score before play started\n",
    "* NflIdRusher - the NflId of the rushing player<br>\n",
    "Rushing, on offense, is running with the ball when starting from behind the line of scrimmage with an intent of gaining yardage. While this usually means a running play, any offensive play that does not involve a forward pass is a rush - also called a run. It is usually done by the running back after a handoff from the quarterback, although quarterbacks and wide receivers can also rush. The quarterback will usually run when a passing play has broken down – such as when there is no receiver open to catch the ball – and there is room to run down the field.\n",
    "* OffenseFormation - offense formation\n",
    "* OffensePersonnel - offensive team positional grouping\n",
    "* DefendersInTheBox - number of defenders lined up near the line of scrimmage, spanning the width of the offensive line\n",
    "* DefensePersonnel - defensive team positional grouping\n",
    "* PlayDirection - direction the play is headed\n",
    "* TimeHandoff - UTC time of the handoff<br>\n",
    "In American football, a hand-off is the act of handing the ball directly from one player to another, i. e. without it leaving the first player's hands.Most rushing plays on offense begin with a handoff from the quarterback to another running back.\n",
    "* TimeSnap - UTC time of the snap <br>\n",
    "A snap (colloquially called a \"hike\", \"snapback\", or \"pass from center\") is the backwards passing of the ballat the start of play from scrimmage.\n",
    "* Yards - the yardage gained on the play (you are predicting this)\n",
    "* PlayerHeight - player height (ft-in)\n",
    "* PlayerWeight - player weight (lbs)\n",
    "* PlayerBirthDate - birth date (mm/dd/yyyy)\n",
    "* PlayerCollegeName - where the player attended college\n",
    "* Position - the player's position (the specific role on the field that they typically play)\n",
    "* HomeTeamAbbr - home team abbreviation\n",
    "* VisitorTeamAbbr - visitor team abbreviation\n",
    "* Week - week into the season\n",
    "* Stadium - stadium where the game is being played\n",
    "* Location - city where the game is being player\n",
    "* StadiumType - description of the stadium environment\n",
    "* Turf - description of the field surface\n",
    "* GameWeather - description of the game weather\n",
    "* Temperature - temperature (deg F)\n",
    "* Humidity - humidity\n",
    "* WindSpeed - wind speed in miles/hour\n",
    "* WindDirection - wind direction\n",
    "<img src=\"columns_visualization.png\">\n",
    "<img src=\"down_and_distance.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "I'm not familiar with american football, so at the beginning I want to understand what it's about for a better data exploration. The offence is given 4 chances (or 4 downs) to make at least 10 yards. If they do so, they retain the possesion and have another 4 chances to move 10 yards. Otherwise, the defending team gets the ball at that point\n",
    "\n",
    "Each team usually consists of 3 units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Offensive unit<br>\n",
    "<img src=\"offensive_unit.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defensive unit<br>\n",
    "<img src=\"defensive_unit.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Special teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 different ways of scoring:\n",
    "1. Touchdown - 6 points - the ball is carried into the endzone or thrown into the endzone and caught\n",
    "2. Extra points - after a touchdown is scored: kick through the uprights (1 point) or try to get the ball to the endzone again for 2 points (most team go for the kick)\n",
    "3. Field goal - a ball must be passed to a player who will hold the ball at the ground ready for the kicker to make a kick, a successful kick scores 3 points\n",
    "4. Safety - if the defense tackles the defensive player behind his own goal line, the defensive team gets 2 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fumble - when the ball carrier drops the ball on the ground, the team that recovers it gets the posession.\n",
    "* Interception - intercepting passes\n",
    "* Sack - defense tackles the quarterback while he has the ball (down is wasted)\n",
    "* Incomplete pass - when a pass touches the ground before reaching the receiver or goes out (down is wasted)\n",
    "* Penalty - after a player makes a foul his team is penalized some yards\n",
    "* Challenge - same as in tennis\n",
    "* Timeout - each team has 3 timeouts per half, each timeout lasts 60 seconds\n",
    "* Line of scrimmage - an imaginary transverse line (across the width of the football field) beyond which a team cannot cross until the next play has begun. Its location is based on the spot where the ball is placed after the end of the most recent play and following the assessment of any penalty yards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data standardization\n",
    "Source: https://www.kaggle.com/cpmpml/initial-wrangling-voronoi-areas-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:25:12.189323Z",
     "start_time": "2019-11-02T12:24:50.198731Z"
    }
   },
   "outputs": [],
   "source": [
    "data['ToLeft'] = data.PlayDirection == \"left\"\n",
    "data['IsBallCarrier'] = data.NflId == data.NflIdRusher\n",
    "data['Dir_rad'] = np.mod(90 - data.Dir, 360) * math.pi/180.0\n",
    "\n",
    "# is that way more efficient?\n",
    "data['TeamOnOffense'] = \"home\"\n",
    "data.loc[data.PossessionTeam != data.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "\n",
    "data['IsOnOffense'] = data.Team == data.TeamOnOffense # Is player on offense?\n",
    "\n",
    "data['YardLine_std'] = 100 - data.YardLine\n",
    "data.loc[data.FieldPosition.fillna('') == data.PossessionTeam,  'YardLine_std'] = data.loc[data.FieldPosition.fillna('') == data.PossessionTeam, 'YardLine']\n",
    "\n",
    "data['X_std'] = data.X\n",
    "data.loc[data.ToLeft, 'X_std'] = 120 - data.loc[data.ToLeft, 'X'] \n",
    "\n",
    "data['Y_std'] = data.Y\n",
    "data.loc[data.ToLeft, 'Y_std'] = 160/3 - data.loc[data.ToLeft, 'Y'] \n",
    "\n",
    "data['Dir_std'] = data.Dir_rad\n",
    "data.loc[data.ToLeft, 'Dir_std'] = np.mod(np.pi + data.loc[data.ToLeft, 'Dir_rad'], 2*np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first clean the values to make the job easier for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:14:57.78661Z",
     "start_time": "2019-11-02T12:14:57.655958Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:25:22.553236Z",
     "start_time": "2019-11-02T12:25:12.190297Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Cleaning team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:25:22.553236Z",
     "start_time": "2019-11-02T12:25:12.190297Z"
    }
   },
   "outputs": [],
   "source": [
    "teams = {'ARI':'ARZ','BAL':'BLT','CLE':'CLV', 'HOU':'HST'}\n",
    "\n",
    "for old_name in teams:\n",
    "    new_name = teams[old_name]\n",
    "    data.replace(old_name, new_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:26:08.563148Z",
     "start_time": "2019-11-02T12:25:22.555231Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Cleaning stadium names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:26:08.563148Z",
     "start_time": "2019-11-02T12:25:22.555231Z"
    }
   },
   "outputs": [],
   "source": [
    "stadiums =  {'Broncos Stadium at Mile High':'Broncos Stadium At Mile High','CenturyLink':'CenturyLink Field',\n",
    "             'CenturyField':'CenturyLink Field','Everbank Field':'EverBank Field', 'First Energy Stadium':'FirstEnergy Stadium',\n",
    "            'FirstEnergy':'FirstEnergy Stadium','FirstEnergyStadium':'FirstEnergy Stadium', 'Lambeau field':'Lambeau Field',\n",
    "             'Los Angeles Memorial Coliesum':'Los Angeles Memorial Coliseum','M & T Bank Stadium':'M&T Bank Stadium',\n",
    "            'M&T Stadium':'M&T Bank Stadium','Mercedes-Benz Dome':'Mercedes-Benz Stadium','MetLife':'MetLife Stadium',\n",
    "            'Metlife Stadium':'MetLife Stadium','NRG':'NRG Stadium','Oakland Alameda-County Coliseum':'Oakland-Alameda County Coliseum',\n",
    "            'Paul Brown Stdium':'Paul Brown Stadium', 'Twickenham':'Twickenham Stadium'}\n",
    "\n",
    "for old_name in stadiums:\n",
    "    new_name = stadiums[old_name]\n",
    "    data.replace(old_name, new_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:26:51.931961Z",
     "start_time": "2019-11-02T12:26:08.565143Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Cleaning stadium types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:26:51.931961Z",
     "start_time": "2019-11-02T12:26:08.565143Z"
    }
   },
   "outputs": [],
   "source": [
    "isOpen = data['StadiumType'].str.contains('open', case=False) | data['StadiumType'].str.contains('outdoor', case=False)\n",
    "isClosed = data['StadiumType'].str.contains('closed', case=False) | data['StadiumType'].str.contains('indoor', case=False)\n",
    "\n",
    "data.loc[isOpen,'StadiumType'] = 'Open'\n",
    "data.loc[isClosed,'StadiumType'] = 'Closed'\n",
    "\n",
    "data.loc[data['Stadium']==\"TIAA Bank Field\",'StadiumType'] = 'Open'\n",
    "data.loc[data['Stadium']==\"StubHub Center\",'StadiumType'] = 'Open'\n",
    "data.loc[data['Stadium']=='MetLife Stadium','StadiumType'] = 'Open'\n",
    "\n",
    "\n",
    "stadium_types = {\"Heinz Field\":\"Open\",\"Dome\":\"Retractable Roof\",\"Outddors\":\"Open\",\"Oudoor\":\"Open\",\n",
    "                 \"Ourdoor\":\"Open\",\"Outdor\":\"Open\",\"Outside\":\"Open\",\"Domed\":\"Closed\"}\n",
    "\n",
    "for old_name in stadium_types:\n",
    "    new_name = stadium_types[old_name]\n",
    "    data.replace(old_name, new_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:27:00.435737Z",
     "start_time": "2019-11-02T12:26:51.933952Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.violinplot(x=\"StadiumType\", y='Yards', data=data[data['Yards']<30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violinplots for all three values seem roughly the same, so it does not seem that the StadiumType variables will be very helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some duplicates and typos in Location, let's fix the typos and split it into city and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:28:15.465536Z",
     "start_time": "2019-11-02T12:27:00.437731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:28:15.465536Z",
     "start_time": "2019-11-02T12:27:00.437731Z"
    }
   },
   "outputs": [],
   "source": [
    "locations = {'Orchard Park NY':'Orchard Park, NY','Orchard Park':'Orchard Park, NY','Chicago. IL':'Chicago, IL',\n",
    "             'Cleveland Ohio':'Cleveland, OH', 'Jacksonville Florida':'Jacksonville, FL','Pittsburgh':'Pittsburgh, PA',\n",
    "            'Detroit':'Detroit, MA','London':'London, England',\n",
    "        'Mexico City':'Mexico City, Mexico','Seattle':'Seattle, WA','Cleveland':'Cleveland, OH', 'New Orleans':'New Orleans, LA'}\n",
    "\n",
    "for old_name in locations:\n",
    "    new_name = locations[old_name]\n",
    "    data.replace(old_name, new_name, inplace=True)\n",
    "    \n",
    "location = data['Location'].str.split(',', expand=True)\n",
    "data['City'] = location[0]\n",
    "data['State'] = location[1].str.strip()\n",
    "\n",
    "states = {'Calif.':'CA','FLA':'FL','Fl':'FL','Fla.':'FL','Florida':'FL', 'Ind.':'IN','La.':'LA','Ma':'MA','Maryland':'MA',\n",
    "         'Md.':'MD', 'N.J.':'NJ', 'North Carolina':'NC', 'Ohio':'OH', 'Pa.':'PA','Texas':'TX'}\n",
    "\n",
    "for old_name in states:\n",
    "    new_name = states[old_name]\n",
    "    data.replace(old_name, new_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:28:20.333439Z",
     "start_time": "2019-11-02T12:28:15.466534Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.boxplot(x='State',y='Yards',data=data[(data['Yards']<10) & (data['Yards']>-5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wasn't certain about the PlayerCollegeName column so I left it intact for now. Maybe creating a variable indicating in which state the player went to college could be helpful. Position looks sort of clean. I would like to experiment by building the same models based on different positions, so for example only model based on QBs and only on TEs and so on. This would indicate which position's data is the most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First standardize the directions according to 16-point compass rose. Then maybe make features like if player runs against the wind. However, for that we would need orientation of the stadium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T10:44:23.228182Z",
     "start_time": "2019-11-02T10:44:23.223227Z"
    }
   },
   "source": [
    "<img src=\"Compass_Rose_English_North.svg.png\" width=200 align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:30:06.725423Z",
     "start_time": "2019-11-02T12:28:20.335434Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Cleaning WindDirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:30:06.725423Z",
     "start_time": "2019-11-02T12:28:20.335434Z"
    }
   },
   "outputs": [],
   "source": [
    "wind_directions = {'South':'S','North':'N','West':'W', 'East':'E','Northwest':'NW','SouthWest':'SW','Northeast':'NE','From S':'S',\n",
    "     'South Southeast':'SSE','From SW':'SW','s':'S', 'NorthEast':'NE','from W':'W', 'W-NW':'WNW','South Southwest':'SSW',\n",
    "     'Southeast':'SE','From WSW':'WSW', 'West Northwest':'WNW','From SSE':'SSE','From W':'W', 'East North East':'ENE',\n",
    "     'From ESE':'ESE','EAST':'E','East Southeast':'ESE','From SSW':'SSW','North East':'NE', 'Southwest':'SW', \n",
    "     'North/Northwest':'NNW', 'From NNE':'NNE','N-NE':'NNE','W-SW':'WSW', 'From NNW':'NNW','West-Southwest':'WSW',\n",
    "     'Calm':'Missing','8':'Missing','1':'Missing','13':'Missing'}\n",
    "\n",
    "for old_name in wind_directions:\n",
    "    new_name = wind_directions[old_name]\n",
    "    data.replace(old_name, new_name, inplace=True)\n",
    "    \n",
    "data.loc[(data['WindDirection'].isna()),'WindDirection'] = 'Missing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite cumbersome to change the type to int due to NaNs, so to avoid the trouble, I changed the type to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:30:25.100098Z",
     "start_time": "2019-11-02T12:30:06.726342Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Cleaning WindSpeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:30:25.100098Z",
     "start_time": "2019-11-02T12:30:06.726342Z"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[data['WindSpeed']=='14-23','WindSpeed'] = 18\n",
    "data.loc[data['WindSpeed']=='11-17','WindSpeed'] = 16\n",
    "data.loc[data['WindSpeed']=='12-22','WindSpeed'] = 17\n",
    "data.loc[data['WindSpeed']=='15 gusts up to 25','WindSpeed'] = 20\n",
    "# some WindSpeed values contains characters, so below we just extract the numbers, e.g.\"15 MPH\" will be changed to 15\n",
    "data['WindSpeed'] = data['WindSpeed'].astype(str).str.extract('(\\d+)')[0].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:30:51.16452Z",
     "start_time": "2019-11-02T12:30:25.102093Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Cleaning GameWeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:30:51.16452Z",
     "start_time": "2019-11-02T12:30:25.102093Z"
    }
   },
   "outputs": [],
   "source": [
    "rainy = ['Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "         'Cloudy, 50% change of rain','Cloudy, Rain','Light Rain','Rain','Rain Chance 40%', \n",
    "         'Rain likely, temps in low 40s.', 'Rain shower', 'Rainy', 'Scattered Showers', 'Showers',]\n",
    "clear = ['Clear','Clear Skies','Clear and Cool','Clear and Sunny','Clear and cold','Clear and sunny','Clear and warm',\n",
    "         'Clear skies','Partly clear',]\n",
    "snowy = ['Cloudy, light snow accumulating 1-3\"','Heavy lake effect snow','Snow']\n",
    "sunny = ['Mostly Sunny', 'Mostly Sunny Skies','Mostly sunny','Partly Sunny','Partly sunny','Sunny',\n",
    " 'Sunny Skies', 'Sunny and clear', 'Sunny and cold', 'Sunny and warm', 'Sunny, Windy', 'Sunny, highs to upper 80s',]\n",
    "cloudy = ['30% Chance of Rain','Cloudy', 'Cloudy and Cool', 'Cloudy and cold','Cloudy, chance of rain',\n",
    "          'Cloudy, fog started developing in 2nd quarter','Coudy','Mostly Cloudy','Mostly Coudy','Mostly cloudy',\n",
    "          'Overcast','Partly Cloudy','Partly Clouidy','Partly cloudy','Party Cloudy','Sun & clouds','cloudy']\n",
    "\n",
    "data['GameWeatherGrouped'] = 'Other'\n",
    "data.loc[data['StadiumType']=='Closed','GameWeatherGrouped'] = 'Indoor'\n",
    "data.loc[data['GameWeather'].isin(rainy),'GameWeatherGrouped'] = 'Rainy'\n",
    "data.loc[data['GameWeather'].isin(clear),'GameWeatherGrouped'] = 'Clear'\n",
    "data.loc[data['GameWeather'].isin(snowy),'GameWeatherGrouped'] = 'Snowy'\n",
    "data.loc[data['GameWeather'].isin(sunny),'GameWeatherGrouped'] = 'Sunny'\n",
    "data.loc[data['GameWeather'].isin(cloudy),'GameWeatherGrouped'] = 'Cloudy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:14.37314Z",
     "start_time": "2019-11-02T12:30:51.166484Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Cleaning Turf - add a isNatural column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:14.37314Z",
     "start_time": "2019-11-02T12:30:51.166484Z"
    }
   },
   "outputs": [],
   "source": [
    "data['isNatural'] = False\n",
    "isNatural = data['Turf'].str.contains('natural', case=False) | data['Turf'].str.contains('grass', case=False)\n",
    "data.loc[isNatural,'isNatural'] = True\n",
    "data.loc[isNatural,'Turf'] = 'Natural grass'\n",
    "\n",
    "turfs = {'Artifical':'Artificial','Field Turf':'FieldTurf','Field turf':'FieldTurf','FieldTurf360':'FieldTurf 360',\n",
    "        'UBU Sport Speed S5-M':'UBU Speed Series-S5-M'}\n",
    "\n",
    "for old_name in turfs:\n",
    "    new_name = turfs[old_name]\n",
    "    data.replace(old_name, new_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:19.00645Z",
     "start_time": "2019-11-02T12:31:14.375134Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Parsing PlayerBirthDate to datetime and adding Age variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:19.00645Z",
     "start_time": "2019-11-02T12:31:14.375134Z"
    }
   },
   "outputs": [],
   "source": [
    "data['PlayerBirthDate'] = pd.to_datetime(data['PlayerBirthDate'],format='%m/%d/%Y')\n",
    "\n",
    "current = datetime.datetime(2019, 11, 1)\n",
    "\n",
    "data['PlayerAge'] = (current-data['PlayerBirthDate']).apply(lambda x: int(x.days/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:20.087597Z",
     "start_time": "2019-11-02T12:31:19.008416Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Converting player height from string in feet to centimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:20.087597Z",
     "start_time": "2019-11-02T12:31:19.008416Z"
    }
   },
   "outputs": [],
   "source": [
    "height_feet = data['PlayerHeight'].str.split('-',expand=True)\n",
    "data['PlayerHeightCm'] = 30.48*height_feet[0].astype(float)+2.54*height_feet[1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:21.351807Z",
     "start_time": "2019-11-02T12:31:20.089592Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Converting GameClock which is relative to the quarter to TimeElapsed that is relative to the whole game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:21.351807Z",
     "start_time": "2019-11-02T12:31:20.089592Z"
    }
   },
   "outputs": [],
   "source": [
    "game_clock = data['GameClock'].str.split(':', expand=True)\n",
    "data['TimeElapsed'] = data['Quarter']*15*60+game_clock[0].astype(int)*60+game_clock[1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:22.38356Z",
     "start_time": "2019-11-02T12:31:21.3538Z"
    }
   },
   "outputs": [],
   "source": [
    "data['GameClock'] = pd.to_datetime(data['GameClock'].str.slice(0,5), format='%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column candidates for removal\n",
    "FieldPosition indicates on which team's half the play is happening. Probably it can be deleted, but let's leave it for now. After executing the code below, the attacking team will always attack from left to right. Therefore, we can probably delete the PlayDirection column. DisplayName which is player name is also redundant for training because we already have NflId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T12:31:50.388976Z",
     "start_time": "2019-11-02T12:31:22.385555Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.to_csv(\"train_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:00:10.702134Z",
     "start_time": "2019-11-06T12:00:07.334602Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"train_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:00:10.709089Z",
     "start_time": "2019-11-06T12:00:10.704102Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:00:10.737014Z",
     "start_time": "2019-11-06T12:00:10.711084Z"
    }
   },
   "outputs": [],
   "source": [
    "score_col = ['HomeScoreBeforePlay','VisitorScoreBeforePlay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:00:10.787879Z",
     "start_time": "2019-11-06T12:00:10.738012Z"
    }
   },
   "outputs": [],
   "source": [
    "data['OffenseFormation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe splitting the OffensePersonnel variable into objects could improve the score. OL stands for Offensive Lineman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:00:10.842833Z",
     "start_time": "2019-11-06T12:00:10.789874Z"
    }
   },
   "outputs": [],
   "source": [
    "offense_formations = data['OffensePersonnel'].unique()\n",
    "print('Possible offensive positions',list(set(re.findall('[A-Z]+',offense_formations.sum()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:04:06.632832Z",
     "start_time": "2019-11-06T12:00:10.843842Z"
    }
   },
   "outputs": [],
   "source": [
    "positions = ['OL', 'QB', 'RB', 'TE', 'WR', 'DL', 'DB','LB']\n",
    "nr_positions = ['Offense #'+pos for pos in positions]\n",
    "\n",
    "for pos in nr_positions: data[pos] = 0\n",
    "\n",
    "for formation in offense_formations:\n",
    "    pos_list = [p.strip() for p in formation.split(',')]\n",
    "#     print(pos_list)\n",
    "    df_values = np.zeros(len(positions),int)\n",
    "    for pos in pos_list:\n",
    "        for i, p in enumerate(positions):\n",
    "            if p in pos:\n",
    "                df_values[i] = pos[0]\n",
    "    if 'QB' not in formation:\n",
    "        df_values[1] = 1\n",
    "    if 'OL' not in formation:\n",
    "        df_values[0] = 11-sum(df_values)\n",
    "    data.loc[data['OffensePersonnel']==formation, nr_positions] = df_values\n",
    "#     print('Formation',formation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:04:06.648767Z",
     "start_time": "2019-11-06T12:04:06.632832Z"
    }
   },
   "outputs": [],
   "source": [
    "# data[['OffensePersonnel']+nr_positions].drop_duplicates(subset='OffensePersonnel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:04:06.677689Z",
     "start_time": "2019-11-06T12:04:06.651759Z"
    }
   },
   "outputs": [],
   "source": [
    "# data['FieldPosition'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same remarks as for offense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:04:06.72257Z",
     "start_time": "2019-11-06T12:04:06.679684Z"
    }
   },
   "outputs": [],
   "source": [
    "defense_formations = data['DefensePersonnel'].unique()\n",
    "print('Possible defensive positions',list(set(re.findall('[A-Z]+',defense_formations.sum()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:40.44125Z",
     "start_time": "2019-11-06T12:04:06.724564Z"
    }
   },
   "outputs": [],
   "source": [
    "positions = ['DL', 'OL', 'DB', 'LB']\n",
    "nr_positions = ['Defense #'+pos for pos in positions]\n",
    "\n",
    "for pos in nr_positions: data[pos] = 0\n",
    "\n",
    "for formation in defense_formations:\n",
    "    pos_list = [p.strip() for p in formation.split(',')]\n",
    "    df_values = np.zeros(len(positions),int)\n",
    "    for pos in pos_list:\n",
    "        for i, p in enumerate(positions):\n",
    "            if p in pos:\n",
    "                df_values[i] = pos[0]\n",
    "    data.loc[data['DefensePersonnel']==formation, nr_positions] = df_values\n",
    "#     print('Formation',formation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:40.50109Z",
     "start_time": "2019-11-06T12:06:40.442247Z"
    }
   },
   "outputs": [],
   "source": [
    "# data[['DefensePersonnel']+nr_positions].drop_duplicates(subset='DefensePersonnel').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:41.20125Z",
     "start_time": "2019-11-06T12:06:40.502087Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # plt.figure(figsize = (20,20))\n",
    "# s = data.drop_duplicates(subset='PlayId')\n",
    "# sns.stripplot(x='Offense #TE', y='Yards',data=s,jitter=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:41.638051Z",
     "start_time": "2019-11-06T12:06:41.202217Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.violinplot(x='Offense #TE', y='Yards',data=s,jitter=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:42.299285Z",
     "start_time": "2019-11-06T12:06:41.639048Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# sns.stripplot(x='Defense #DL', y='Yards',data=s,jitter=.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:42.733978Z",
     "start_time": "2019-11-06T12:06:42.300283Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.violinplot(x='Defense #DL', y='Yards',data=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:42.739935Z",
     "start_time": "2019-11-06T12:06:42.734964Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:54:26.471007Z",
     "start_time": "2019-11-06T11:54:26.454014Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.to_csv('train_cleaned_formations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:42.795392Z",
     "start_time": "2019-11-06T12:06:42.740931Z"
    }
   },
   "outputs": [],
   "source": [
    "# data[data['Yards']<0].shape[0]/data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 11% of plays the offensive team looses yards instead of gaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:42.820293Z",
     "start_time": "2019-11-06T12:06:42.796359Z"
    }
   },
   "outputs": [],
   "source": [
    "# data['Yards'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:43.202443Z",
     "start_time": "2019-11-06T12:06:42.821291Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.distplot(data['Yards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:43.239349Z",
     "start_time": "2019-11-06T12:06:43.2034Z"
    }
   },
   "outputs": [],
   "source": [
    "# team name of the player\n",
    "data['TeamName'] = np.where(data['Team']=='away', data['VisitorTeamAbbr'], data['HomeTeamAbbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:06:43.262398Z",
     "start_time": "2019-11-06T12:06:43.240307Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:08:15.921998Z",
     "start_time": "2019-11-06T12:06:43.264378Z"
    }
   },
   "outputs": [],
   "source": [
    "def closestOpponent(x):\n",
    "    coords = ['X_std','Y_std']\n",
    "#     get rusher index\n",
    "    rusher_ix = x[x['NflId']==x['NflIdRusher']].index[0]\n",
    "#     get rusher X and Y\n",
    "    rusher_coords = data.at[rusher_ix,'X_std'],data.at[rusher_ix,'Y_std']\n",
    "#     get coords of defensive team\n",
    "    defensive_team_coords = x[x['PossessionTeam']!=x['TeamName']][coords]\n",
    "#     get euclidean distance between each deffense team player and the rusher\n",
    "    euclideanDis = (defensive_team_coords-rusher_coords).pow(2).sum(1).pow(0.5)\n",
    "#     get minimal distance to the rusher\n",
    "    return euclideanDis.min()\n",
    "\n",
    "d = data.groupby(by='PlayId').apply(closestOpponent)\n",
    "\n",
    "data['ClosestOpponent'] = [d[x] for x in data['PlayId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.data-to-viz.com/caveat/overplotting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:08:16.389959Z",
     "start_time": "2019-11-06T12:08:15.921998Z"
    }
   },
   "outputs": [],
   "source": [
    "x = data['ClosestOpponent']\n",
    "y = data['Yards']\n",
    "h =plt.hist2d(x, y)\n",
    "plt.colorbar(h[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:08:17.722367Z",
     "start_time": "2019-11-06T12:08:16.391954Z"
    }
   },
   "outputs": [],
   "source": [
    "# a = sns.jointplot(x='ClosestOpponent', y='Yards',data=data, kind='hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:08:17.809135Z",
     "start_time": "2019-11-06T12:08:17.724363Z"
    }
   },
   "outputs": [],
   "source": [
    "# rushers = data[data.NflId==data.NflIdRusher].copy()\n",
    "# rushers['DistRushScrimmage'] = (rushers['YardLine_std']+10-rushers['X_std']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:08:18.107183Z",
     "start_time": "2019-11-06T12:08:17.810132Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.distplot(rushers['DistRushScrimmage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:08:18.116696Z",
     "start_time": "2019-11-06T12:08:18.107183Z"
    }
   },
   "outputs": [],
   "source": [
    "# rushers['DistRushScrimmage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:08:18.552517Z",
     "start_time": "2019-11-06T12:08:18.118691Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.scatterplot(x='Yards', y='DistRushScrimmage', data=rushers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T15:30:09.937663Z",
     "start_time": "2019-11-02T15:30:01.352659Z"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize = (30,30))\n",
    "\n",
    "# sns.heatmap(data.corr(),vmin=-1,vmax=1,center=0,annot=True)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was expecting a linear relationship but boy was I wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T16:47:42.175996Z",
     "start_time": "2019-10-30T16:47:42.14408Z"
    }
   },
   "outputs": [],
   "source": [
    "# data['YardLine_std'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:08:45.347726Z",
     "start_time": "2019-11-06T12:08:18.553484Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.to_csv('train_proc.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO\n",
    "* Check if it's more difficult to gain yardage close to the defensive team endzone\n",
    "* Prediction processing trick: Remember that the yards gained cant be more than length of the field - line of scrimmage!\n",
    "* Prediction processing trick: For rows with the same PlayId, the Yards must be the same\n",
    "* Get a better intuition what the Dis variables really is, try plotting the points\n",
    "* Try to visualize from the data what happened in the game, retrieve touchdowns, fumbles, interceptions etc. Verify it with a match, you can watch all matches on youtube https://www.youtube.com/channel/UCP4Wts8iiR9-Ddfq7FK0x3g/videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.competitions import nflrush\n",
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('../../kaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data = pd.read_csv('../../kaggle/output/working/train_proc.csv')\n",
    "data = data.drop(['GameClock','PlayerBirthDate'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "cat_vars = data.select_dtypes(include='object').columns\n",
    "cont_vars = data.select_dtypes(exclude='object').columns\n",
    "print(cat_vars)\n",
    "print(cont_vars)\n",
    "cont_medians = {}\n",
    "for col in cont_vars:\n",
    "    print(col)\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "    cont_medians[col] = data[col].median()\n",
    "\n",
    "for col in cat_vars:\n",
    "    data[col] = data[col].fillna('Missing')    \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_dict = {}\n",
    "for col in cat_vars:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(set(data[col].values))+['Missing'])\n",
    "    le_dict[col] = le\n",
    "    data[col] = le.transform(data[col])\n",
    "#     test[col] = le.transform(list(test[col].astype(str).values))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "models = []\n",
    "def train_model(X, y, folds, model_type='lgb', eval_metric='auc', n_jobs=-1, n_estimators=None, plot_feature_importance=True, verbose=500,early_stopping_rounds=200):\n",
    "    result_dict = {}\n",
    "    scores = []\n",
    "    n_splits = folds.n_splits\n",
    "    columns = X.columns\n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros((len(X), 1))\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y,X['GameId'])):\n",
    "        print('Fold nr {}'.format(fold_n))\n",
    "        X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        model = lgb.LGBMRegressor(n_estimators=n_estimators, n_jobs = n_jobs)\n",
    "        model.fit(X_train, y_train, \n",
    "                eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n",
    "                verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "        models.append(model)\n",
    "        y_pred = model.predict(X_valid)\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "        oof[valid_index] = y_pred.reshape(-1, 1)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            best_features = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].reset_index(level=['feature'])\n",
    "\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features);\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "            result_dict['top_columns'] = best_features['feature'].unique()\n",
    "        \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushers = data[data.NflId==data.NflIdRusher]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X = rushers.drop(['Yards'],axis=1)\n",
    "y = rushers['Yards']\n",
    "folds = GroupKFold(n_splits=5)\n",
    "results = train_model(X, y, folds, n_estimators=1000) # a, s, clos, dirstd,gamecloc, dir,orient, x, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tqdm\n",
    "test_dfs = pd.DataFrame(columns=X.columns)\n",
    "for (test_df, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n",
    "    test_df1 = test_df.copy()\n",
    "    \n",
    "    for old_name in teams:\n",
    "        new_name = teams[old_name]\n",
    "        test_df.replace(old_name, new_name, inplace=True)\n",
    "    \n",
    "    test_df['ToLeft'] = test_df.PlayDirection == \"left\"\n",
    "    test_df['X_std'] = test_df.X\n",
    "    test_df.loc[test_df.ToLeft, 'X_std'] = 120 - test_df.loc[test_df.ToLeft, 'X'] \n",
    "    \n",
    "    test_df['Y_std'] = test_df.X\n",
    "    test_df.loc[test_df.ToLeft, 'Y_std'] = 160/3 - test_df.loc[test_df.ToLeft, 'Y'] \n",
    "    \n",
    "    test_df['TeamName'] = np.where(test_df['Team']=='away', test_df['VisitorTeamAbbr'], test_df['HomeTeamAbbr'])\n",
    "    \n",
    "    test_df['ClosestOpponent'] = closestOpponent(test_df)\n",
    "    test_df = test_df[test_df.NflId == test_df.NflIdRusher]\n",
    "    test_df = test_df.iloc[0]\n",
    "    \n",
    "    test_df['ToLeft'] = test_df.PlayDirection == \"left\"\n",
    "    test_df['IsBallCarrier'] = test_df.NflId == test_df.NflIdRusher\n",
    "    test_df['Dir_rad'] = np.mod(90 - test_df.Dir, 360) * math.pi/180.0\n",
    "\n",
    "    if test_df.PossessionTeam != test_df.HomeTeamAbbr:\n",
    "        test_df['TeamOnOffense'] = \"away\"\n",
    "    else:\n",
    "        test_df['TeamOnOffense'] = \"home\"\n",
    "        \n",
    "    test_df['IsOnOffense'] = test_df.Team == test_df.TeamOnOffense # Is player on offense?\n",
    "\n",
    "    \n",
    "    if test_df.FieldPosition == test_df.PossessionTeam:\n",
    "        test_df['YardLine_std'] = test_df['YardLine']\n",
    "    else:\n",
    "        test_df['YardLine_std'] = 100 - test_df.YardLine\n",
    "    \n",
    "    \n",
    "    if test_df['ToLeft']:\n",
    "#         test_df['X_std'] = 120 - test_df.loc['X'] \n",
    "#         test_df.loc['Y_std'] = 160/3 - test_df['Y']\n",
    "        test_df['Dir_std'] = np.mod(np.pi + test_df['Dir_rad'], 2*np.pi)\n",
    "    else:\n",
    "#         test_df['X_std'] = test_df.X\n",
    "#         test_df['Y_std'] = test_df.Y\n",
    "        test_df['Dir_std'] = test_df.Dir_rad\n",
    "        \n",
    "\n",
    "    \n",
    "    if test_df.Stadium in stadiums:\n",
    "        test_df.Stadium = stadiums[test_df.Stadium]\n",
    "    elif test_df.Stadium not in data.Stadium.unique():\n",
    "        test_df.Stadium = 'Missing'\n",
    "    # Cleaning stadium types\n",
    "    try:\n",
    "        isOpen = test_df['StadiumType'].str.contains('open', case=False) | test_df['StadiumType'].str.contains('outdoor', case=False)\n",
    "        isClosed = test_df['StadiumType'].str.contains('closed', case=False) | test_df['StadiumType'].str.contains('indoor', case=False)\n",
    "        print('isOpen {} isClosed {}'.format(isOpen,isClosed))\n",
    "\n",
    "        if isOpen or test_df['Stadium']==\"TIAA Bank Field\" or test_df['Stadium']==\"StubHub Center\" or test_df['Stadium']=='MetLife Stadium':\n",
    "            test_df['StadiumType'] = 'Open'\n",
    "        elif isClosed:\n",
    "            test_df.loc['StadiumType'] = 'Closed'\n",
    "        elif test_df.StadiumType in stadium_types:\n",
    "            test_df.StadiumType = stadium_types[test_df.StadiumType]\n",
    "            \n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        test_df['StadiumType'] = 'Missing'\n",
    "\n",
    "    \n",
    "    if test_df.Location in locations:\n",
    "        test_df.Location = locations[test_df.Location]\n",
    "    elif test_df.Location not in data.Location.unique():\n",
    "        test_df.Location = 'Missing'\n",
    "#         /here\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        location = test_df['Location'].split(',')\n",
    "        test_df['City'] = location[0]\n",
    "        test_df['State'] = location[1].strip()\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        test_df['City'] = 'Missing'\n",
    "        test_df['State'] = 'Missing'\n",
    "\n",
    "\n",
    "    if test_df.State in states:\n",
    "        test_df.State = states[test_df.State]\n",
    "\n",
    "    if test_df.WindDirection in wind_directions:\n",
    "        test_df.WindDirection = wind_directions[test_df.WindDirection]\n",
    "    elif test_df.WindDirection not in data.WindDirection.unique():\n",
    "        test_df.WindDirection = 'Missing'\n",
    "\n",
    "    wind_speed = {'14-23':18,'11-17':16,'12-22':17,'15 gusts up to 25':20}\n",
    "\n",
    "    if test_df.WindSpeed in wind_speed:\n",
    "        test_df.WindSpeed = wind_speed[test_df.WindSpeed]\n",
    "    else:\n",
    "        try:\n",
    "            # some WindSpeed values contains characters, so below we just extract the numbers, e.g.\"15 MPH\" will be changed to 15\n",
    "            test_df['WindSpeed'] = float(re.findall('(\\d+)',str(test_df['WindSpeed']))[0])\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            test_df['WindSpeed'] = np.nan\n",
    "            \n",
    "    if test_df.StadiumType=='Closed':\n",
    "        test_df['GameWeatherGrouped'] = 'Indoor'\n",
    "    elif test_df.GameWeather in rainy:\n",
    "        test_df['GameWeatherGrouped'] = 'Rainy'\n",
    "    elif test_df.GameWeather in clear:\n",
    "        test_df['GameWeatherGrouped'] = 'Clear'\n",
    "    elif test_df.GameWeather in snowy:\n",
    "        test_df['GameWeatherGrouped'] = 'Snowy'\n",
    "    elif test_df.GameWeather in sunny:\n",
    "        test_df['GameWeatherGrouped'] = 'Sunny'\n",
    "    elif test_df.GameWeather in cloudy:\n",
    "        test_df['GameWeatherGrouped'] = 'Cloudy'\n",
    "    else:\n",
    "        test_df['GameWeatherGrouped'] = 'Other'\n",
    "\n",
    "\n",
    "\n",
    "    isNatural = 'natural' in test_df['Turf'].lower() or 'grass' in test_df['Turf'].lower()\n",
    "    test_df['isNatural'] = isNatural\n",
    "    print(test_df.isNatural)\n",
    "    if isNatural:\n",
    "        test_df['Turf'] = 'Natural grass'\n",
    "    elif test_df.Turf in turfs:\n",
    "        test_df.Turf = turfs[test_df.Turf]\n",
    "    elif test_df.Turf not in data.Turf.unique():\n",
    "        test_df.Turf = 'Missing'\n",
    "\n",
    "    test_df['PlayerBirthDate'] = pd.to_datetime(test_df['PlayerBirthDate'],format='%m/%d/%Y')\n",
    "\n",
    "    test_df['PlayerAge'] = int((current-test_df['PlayerBirthDate']).days/365)\n",
    "\n",
    "    # Converting player height from string in feet to centimeters\n",
    "    height_feet = test_df['PlayerHeight'].split('-')\n",
    "    test_df['PlayerHeightCm'] = 30.48*float(height_feet[0])+2.54*float(height_feet[1])\n",
    "\n",
    "    # Converting GameClock which is relative to the quarter to TimeElapsed that is relative to the whole game\n",
    "    game_clock = test_df['GameClock'].split(':')\n",
    "    test_df['TimeElapsed'] = test_df['Quarter']*15*60+int(game_clock[0])*60+int(game_clock[1])\n",
    "\n",
    "    # doubt\n",
    "    test_df = test_df.drop(['GameClock','PlayerBirthDate'])\n",
    "    #     test_df['GameClock'] = pd.to_datetime(test_df['GameClock'].str.slice(0,5), format='%M:%S')\n",
    "    positions = ['OL', 'QB', 'RB', 'TE', 'WR', 'DL', 'DB','LB']\n",
    "    nr_positions = ['Offense #'+pos for pos in positions]\n",
    "\n",
    "    for pos in nr_positions: test_df[pos] = 0\n",
    "    #     offense_formations = test_df['OffensePersonnel'].unique()\n",
    "    #     print('Possible offensive positions',list(set(re.findall('[A-Z]+',offense_formations.sum()))))\n",
    "    formation =test_df['OffensePersonnel']\n",
    "    pos_list = [p.strip() for p in formation.split(',')]\n",
    "    df_values = np.zeros(len(positions),int)\n",
    "    for pos in pos_list:\n",
    "        for i, p in enumerate(positions):\n",
    "            if p in pos:\n",
    "                df_values[i] = pos[0]\n",
    "    if 'QB' not in formation:\n",
    "        df_values[1] = 1\n",
    "    if 'OL' not in formation:\n",
    "        df_values[0] = 11-sum(df_values)\n",
    "    test_df[nr_positions] = df_values\n",
    "\n",
    "    #     print('Formation',formation)\n",
    "    #     defense_formations = test_df['DefensePersonnel'].unique()\n",
    "    #     print('Possible defensive positions',list(set(re.findall('[A-Z]+',defense_formations.sum()))))\n",
    "    positions = ['DL', 'OL', 'DB', 'LB']\n",
    "    nr_positions = ['Defense #'+pos for pos in positions]\n",
    "\n",
    "    for pos in nr_positions: test_df[pos] = 0 \n",
    "    formation = test_df['DefensePersonnel']\n",
    "    pos_list = [p.strip() for p in formation.split(',')]\n",
    "    df_values = np.zeros(len(positions),int)\n",
    "    for pos in pos_list:\n",
    "        for i, p in enumerate(positions):\n",
    "            if p in pos:\n",
    "                df_values[i] = pos[0]\n",
    "    test_df[nr_positions] = df_values\n",
    "\n",
    "    test_df = pd.DataFrame(test_df).transpose()\n",
    "    for col in cont_vars:\n",
    "        if col!='Yards':\n",
    "            test_df[col] = test_df[col].fillna(cont_medians[col])\n",
    "    for col in cat_vars:\n",
    "        test_df[col] = test_df[col].fillna('Missing')\n",
    "        \n",
    "    test_dfs = test_dfs.append(test_df)\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for col in cat_vars:\n",
    "        try:\n",
    "            test_df[col] = le_dict[col].transform(test_df[col])\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            test_df[col] = 'Missing'\n",
    "            test_df[col] = le_dict[col].transform(test_df[col])\n",
    "    #     test[col] = le_dict[col].transform(list(test[col].astype(str).values)) \n",
    "    \n",
    "    folds = 5\n",
    "    y_pred_p = np.sum(np.round([model.predict(test_df)[0] for model in models]))/folds\n",
    "    y_pred = np.zeros(199) \n",
    "    y_pred_p += 99\n",
    "    for j in range(199):\n",
    "        if j>=y_pred_p+10:\n",
    "            y_pred[j]=1.0\n",
    "        elif j>=y_pred_p-10:\n",
    "            y_pred[j]=(j+10-y_pred_p)*0.05\n",
    "    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\n",
    "env.write_submission_file()\n",
    "test_dfs.to_csv('test_dfs.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
